\documentclass[dscexam, EN]{ufabcFHZh}
\input{NewCommands/Input_NewCommand}
\input{NewCommands/Input_NewCommand_Figures}
\togglefalse{LinksComCores} 	
\input{Pacotes/Input_Pacotes}
\input{Pacotes/Input_Pacotes_Listings}
\graphicspath{Figuras/}

% ===================================================================
% LOAD SYMBOLS AND ABBREVIATIONS
\makelosymbols
\makeloabbreviations

\begin{document}

% ===================================================================
% TITLE PAGE
% ===================================================================
\title{Reduced Order Models for Data-Driven Flow Field Flow Reconstruction using Machine Learning}
\foreigntitle{English Title}
\author{}{Allan Moreira de Carvalho}

% ------- Orientador e (se houver) Coorientador
\advisor{Prof. Dr.}{Daniel}{Jonas Dezan}{}
\advisor{Prof. Dr.}{Wallace}{Gusmão Ferreira}{}

% ------- Banca
\examiner{Prof. Dr.}{Marcia Maria Penteado Marchesini}{External Examiner}
\examiner{Prof. Dr.}{Wilson Carlos da Silva Júnior}{External Examiner}
\examiner{Prof. Dr.}{Franciane Freitas Silveira}{Internal Substitute Examiner}
\examiner{Prof. Dr.}{ Rômulo Gonçalves Lins}{Chair}
% ------- Coordenador do curso
\coordinator{Prof.}{Dr.}{NomeCoordenador}{}
% ------ Data de entrega
\date{23}{03}{2022} % dia - mês - ano
% ------ Limite de 5 palavras chaves para ficha catalográfica
\keyword{K1}
\keyword{K2}
\keyword{K3}
\keyword{K4}
\keyword{K5}

% ------ Curso/Programa de pós-graduação
\department{EEN}


\maketitle

% -----------------------------
% ELEMENTOS PRÉ-TEXTUAIS
% -----------------------------
%%%%%%%%%%%================%%%%%%%%%%%
\frontmatter

% Dedicatória
% ------------------------------------------
\dedication{I dedicate it.}

% ------------------------------------------
% AGRADECIMENTOS - Input externo
% ------------------------------------------
\begin{agradecimentos}
	\input{Pre-Textuais/Input_Agr_1_0}
\end{agradecimentos}
% -----------------------------------------

% -----------------------------------------
% EPÍGRAFE - Input externo
% -----------------------------------------
\begin{epigrafe}
	\input{Pre-Textuais/Input_Epi_1_0}
\end{epigrafe}

% --- resumo em inglês
\begin{foreignabstract}
	\input{Pre-Textuais/Input_Abs_1_0}
\end{foreignabstract}
\keywordeng
{Reduced Order Model};
{Data-Driven};
{Machine Learning};
{Fluid Flow Reconstruction}

% --- resumo em português
\begin{abstract}
	\input{Pre-Textuais/Input_Abs_2_0}
\end{abstract}
\palavrachave{Indústria 4.0};
{Modelo de Ordem Reduzida};
{Baseado em Dados};
{Aprendizagem de Máquina};
{Reconstrução de Escomentos de Fluidos}


% -----------------------------------------
% Inserir Lista de Figuras
% -----------------------------------------
\listoffigures

% -----------------------------------------
% Inserir lista de Tabelas
% -----------------------------------------
\listoftables

% -----------------------------------------
% Inserir lista de símbolos e abreviações
% -----------------------------------------
\printloabbreviations
\printlosymbols

% -----------------------------------------
% Inserir lista de Algoritmos
% -----------------------------------------
\printlistofalgorithms

% -----------------------------------------
% Inserir Sumário
% -----------------------------------------
% ************
\makeatletter \let\ps@plain\ps@empty \makeatother % Remove #pag na 1ª pag do sumário
% ************
\tableofcontents
% -----------------------------------------

% ************ Salvar número da página - Para numeração contínua - Não edite esse bloco
\setcounter{pagenumber_frontmatter}{\number\value{page}}

%%%%%%%%%%%================%%%%%%%%%%%
\mainmatter
%%%%%%%%%%%================%%%%%%%%%%%

% ************ Retornar número da página salvo: + 1 no rascunho, + 2 na versão final - Não edite esse bloco
\iftoggle{toggleVersaoFinal}
{\setcounter{page}{\number\value{pagenumber_frontmatter} + 2}}
{\setcounter{page}{\number\value{pagenumber_frontmatter} + 1}}
% ************

% -----------------------------------------
% CAPÍTULOS Inseridos de arquivos externos
%% -----------------------------------------
%\include{Textuais/Introduction}
%\include{Textuais/Bibliography_Review}
%\include{Textuais/Methodology}
%\include{Textuais/Case_Study}

% ===================================================================
% ABSTRACT
% ===================================================================
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This study presents a machine learning-based surrogate modeling framework for reconstructing steady-state two-dimensional nozzle flows under varying flow and geometric conditions. The approach enables accurate prediction of high-fidelity viscous fields using low-dimensional inputs, such as scalar boundary conditions or quasi-one-dimensional (Q1D) solutions. To mitigate the challenges of training on high-dimensional data, Proper Orthogonal Decomposition (POD) is employed for dimensionality reduction, retaining dominant flow features while significantly lowering computational cost. Two regression strategies were investigated: Artificial Neural Networks (ANNs) and Gaussian Processes (GPs). A custom loss function was introduced for ANN models, combining mean squared error in both latent and reconstructed physical spaces, promoting accurate full-field recovery. Hyperparameter tuning was performed using Bayesian Optimization with Hyperband (BOHB), revealing that shallow ANNs with activation functions such as \textit{sigmoid}, \textit{hard sigmoid}, and \textit{swish} consistently yield optimal performance. Comprehensive evaluation across multiple datasets and boundary conditions demonstrated that ANNs generally achieve higher coefficients of determination ($R^2$), while GPs attain lower normalized root mean square error (NRMSE) under large, clean datasets. Robustness tests revealed that ANN models degrade more gracefully under input noise, whereas GPs are more sensitive but outperform ANNs when sufficient clean data are available. K-fold cross-validation confirmed the stability of ANNs in data-scarce regimes, and SHapley Additive exPlanations (SHAP) analysis provided physical insight by identifying the dominant influence of total pressure and the limited effect of wall temperature. This work provides valuable insights and practical guidelines for developing accurate and computationally efficient surrogate models in fluid dynamics.


% ===================================================================
% ACKNOWLEDGEMENTS
% ===================================================================
\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

We gratefully acknowledge the support of the RCGI—Research Centre for Greenhouse Gas Innovation, hosted by the University of São Paulo (USP) and sponsored by FAPESP—São Paulo Research Foundation (2014/50279-4 and 2020/15230-5) and Shell Brasil, and the strategic importance of the support given by ANP (Brazil's National Oil, Natural Gas, and Biofuels Agency) through the R\&D levy regulation. Also, the support of the UFABC—Federal University of ABC, which provides all the computational and physical infrastructure.


% ===================================================================
% TABLE OF CONTENTS, LISTS OF FIGURES AND TABLES
% ===================================================================
\tableofcontents
\listoffigures
\listoftables

% ===================================================================
% CHAPTER 1: INTRODUCTION
% ===================================================================
\chapter{Introduction}

\section{Motivation and Context}

This dissertation addresses the challenge of developing computationally efficient surrogate models to replace resource-intensive Computational Fluid Dynamics (CFD) solvers, particularly during the design and optimization phases of engineering projects. The final objective is to create tools for Project 77 of the Research Centre for Greenhouse Gas Innovation (RCGI), which focuses on designing a centrifugal compressor for carbon capture and storage applications. The high computational demands of CFD simulations in such projects pose a significant bottleneck, especially when extensive evaluations are required for design space exploration and optimization.

To address this challenge, this work explores machine learning-based models as a computatinal affordable alternative to CFD solvers. These models aim to provide fast and accurate predictions of flow fields while remains being sensitive to geometric variations and boundary conditions. 

To validate the proposed framework, preliminary studies were conducted on simpler CFD problems, such as compressible flow in convergent-divergent nozzles and the reconstruction of pressure and temperature fields over blades in NASA Rotor 37. These initial investigations provided valuable insights and served as a foundation for developing surrogate models tailored to the intricate demands of centrifugal compressor design.

\section{Expected Content in the Introduction of a Doctoral Thesis}

The introduction of a doctoral thesis typically serves as the foundation for the entire research work. It is expected to include the following elements:

\begin{itemize}
    \item \textbf{Background and Context:} Provide a brief overview of the research area, highlighting its importance and relevance in the broader scientific or engineering domain.
    \item \textbf{Motivation:} Clearly articulate the reasons for undertaking the research, emphasizing the gaps or challenges in the existing body of knowledge.
    \item \textbf{Problem Statement:} Define the specific problem or question that the thesis aims to address, ensuring it is well-scoped and researchable.
    \item \textbf{Objectives:} Outline the main goals of the research, specifying what the study seeks to achieve.
    \item \textbf{Contributions:} Summarize the novel aspects of the work and its expected impact on the field.
    \item \textbf{Thesis Structure:} Provide a roadmap of the thesis, briefly describing the content of each chapter to guide the reader.
\end{itemize}

These elements collectively set the stage for the research, ensuring the reader understands the significance, scope, and direction of the work.

\section{Problem Statement and Objectives}

This work proposes a data-driven framework for constructing and optimizing machine-learning-based reduced-order models (ML-ROMs) for flow field reconstruction. The objective is to build a parametric surrogate model capable of reconstructing the flow fields of a supersonic hot air stream within a convergent-divergent nozzle. The model must be able to accurately predict high-fidelity viscous fields from low-dimensional inputs, such as scalar boundary conditions or quasi-one-dimensional (Q1D) solutions.

The main objectives are:
\begin{itemize}
    \item To develop an ML-ROM framework to reconstruct 2D nozzle flow fields from low-dimensional inputs.
    \item To investigate and compare two regression strategies: Artificial Neural Networks (ANNs) and Gaussian Processes (GPs).
    \item To introduce and evaluate a novel loss function for ANNs that combines errors in the latent and physical spaces to improve reconstruction fidelity.
    \item To perform a systematic hyperparameter optimization to find the most effective model architectures.
    \item To rigorously evaluate the performance, robustness, interpretability, and computational efficiency of the developed models.
\end{itemize}

\section{Thesis Contributions}
The main contributions of this work are:
\begin{itemize}
    \item A surrogate modeling framework that reconstructs 2D viscous nozzle flows from low-dimensional inputs using POD-based dimensionality reduction.
    \item A comprehensive evaluation of Artificial Neural Networks (ANNs) and Gaussian Processes (GPs) with extensive hyperparameter tuning via BOHB.
    \item A novel loss function that improves ANN performance by combining latent and physical-space reconstruction errors.
    \item An in-depth analysis of model robustness to data variability (k-fold cross-validation) and input noise, showing the superiority of ANNs in non-ideal data scenarios.
    \item The use of SHAP analysis to reveal the importance of input features, aligning with physical principles and supporting the interpretability of predictions.
    \item The demonstration that surrogate models enable real-time inference, achieving speed-ups of up to $7374\times$ compared to CFD solvers.
\end{itemize}

\section{Thesis Outline}
The remainder of this thesis is organized as follows:
\begin{itemize}
    \item \textbf{Chapter 2} presents the theoretical background, covering the governing equations of fluid dynamics, the nozzle flow modeling, and the theoretical basis for the machine learning methods used.
    \item \textbf{Chapter 3} details the methodology, including the setup of the numerical experiments, the generation of the datasets, and the complete ML-ROM architecture, from preprocessing to hyperparameter optimization.
    \item \textbf{Chapter 4} presents and discusses the results, focusing on model evaluation, robustness, interpretability, computational efficiency, and analysis of the flow field reconstructions.
    \item \textbf{Chapter 5} concludes the work, summarizing the key findings, discussing the limitations, and suggesting directions for future research.
\end{itemize}

\chapter{Literature Review}
\label{chap:lit_review}

\section{Introduction}

This chapter provides a review of the relevant literature, establishing the context for the present work. It begins by outlining the computational challenges in modern fluid dynamics that motivate the development of surrogate models. It then surveys the application of Machine Learning (ML) to the field, with a specific focus on Reduced-Order Models (ROMs) for flow field reconstruction. The state-of-the-art concerning data-driven techniques, particularly those employing Artificial Neural Networks (ANNs) and Gaussian Processes (GPs), is discussed. Finally, this review identifies the specific gaps in the current body of knowledge that this thesis aims to address, thereby positioning its contributions within the broader scientific landscape.

\section{The Challenge of High-Fidelity Flow Simulation}

In modern aerothermodynamic design and optimization, a detailed understanding of the flow field is indispensable. Traditionally, this knowledge is acquired through high-fidelity numerical simulations, such as solving the Reynolds-Averaged Navier–Stokes (RANS) or Large Eddy Simulation (LES) equations. However, these simulations are often computationally expensive, sometimes prohibitively so, especially when numerous evaluations are required for design space exploration, uncertainty quantification, or optimization tasks. This computational bottleneck has spurred the development of surrogate models, which aim to preserve the high accuracy of detailed simulations while drastically reducing the computational cost.

\section{Machine Learning as a Solution in Fluid Dynamics}

Machine Learning (ML), a subfield of Artificial Intelligence, has emerged as a powerful paradigm for modeling complex physical phenomena where governing equations are either unknown or computationally difficult to solve, as is the case with turbulent compressible flows. As noted by researchers such as \citet{mendezChallenges2024}, \citet{Brunton2020}, and \citet{vinuesaEmerging2022}, ML has been successfully applied to a wide array of engineering problems. These applications include, but are not limited to:
\begin{itemize}
    \item Pattern recognition \citep{bishopPattern2006, Groun2022, Salehi2018}
    \item Classification tasks \citep{Wang2016}
    \item Optimization and design \citep{Bock2019, ferreiraEnsemble2018, Kianifar2020, Peters2023}
    \item Flow control \citep{Montans2019, talaeiBoundary2018}
    \item Uncertainty quantification \citep{chuDeep2024, pengApplying2024, liangLiquid2024}
\end{itemize}
Despite these successes, persistent challenges in the application of ML to physical systems remain, particularly concerning model selection, optimization, interpretability, and the generalization of models to unseen conditions.

\section{Reduced-Order Modeling (ROMs)}

Reduced-Order Models (ROMs) are a specific class of surrogate models designed to approximate the behavior of high-dimensional systems using a much smaller number of degrees of freedom. The fundamental goal of a ROM is to capture the most influential dynamics of the system, thereby enabling rapid and efficient predictions.

\subsection{Projection-Based ROMs and Proper Orthogonal Decomposition (POD)}

A cornerstone of many ROM strategies is Proper Orthogonal Decomposition (POD), a technique for data compression and feature extraction that is mathematically equivalent to Principal Component Analysis (PCA). As detailed by \citet{berkoozProper1993} and \citet{taira2017modal}, POD is used in fluid dynamics to identify a set of orthogonal basis functions, or "modes," that capture the maximum possible kinetic energy for any given number of modes. These modes represent the dominant, large-scale coherent structures within the flow.

By projecting the high-dimensional governing equations (e.g., Navier-Stokes) onto a low-dimensional subspace spanned by a truncated set of these POD modes, one can create a computationally inexpensive projection-based ROM. However, these models can struggle with accurately capturing highly nonlinear phenomena or advection-dominated flows.

\section{Data-Driven ROMs for Flow Field Reconstruction}

An alternative and increasingly popular approach is the use of purely data-driven, or non-intrusive, ROMs. These methods learn the mapping between system parameters and the solution field directly from a database of high-fidelity simulation results. Recent studies have demonstrated the immense potential of ML to reconstruct high-dimensional flow fields from reduced or simplified input representations, especially given the availability of large CFD datasets \citep{Zhang2023, Erichson2020b, Deng2021, cahalyPLICNet2024, champenoisMachine2024, xuSelfsupervised2023}. This thesis follows this data-driven paradigm, creating a machine-learning-based reduced-order model (ML-ROM) for flow field reconstruction.

\subsection{Surrogate Models: Artificial Neural Networks and Gaussian Processes}

Within the data-driven framework, various regression algorithms can be employed as the core surrogate model. This work focuses on two of the most prominent techniques: Artificial Neural Networks (ANNs) and Gaussian Processes (GPs).

\begin{itemize}
    \item \textbf{Artificial Neural Networks (ANNs)} are powerful function approximators inspired by the structure of the human brain. Their ability to model highly nonlinear relationships makes them well-suited for complex regression problems. They have been widely used in fluid dynamics for their universal approximation capabilities \citep{Berner2022, Czum2020, Kumar2020}.

    \item \textbf{Gaussian Processes (GPs)} are a nonparametric Bayesian method for regression. Instead of learning a single function, a GP learns a distribution over functions that are consistent with the training data. As described by \citet{rasmussenGaussian2006}, this provides a principled way to quantify prediction uncertainty, which is a significant advantage in many engineering applications \citep{Liu2020, Hasdiana2018a}.
\end{itemize}

\section{Research Gap and Thesis Contribution}

While the application of ML-ROMs for flow reconstruction is an active area of research, several gaps remain. Many existing studies focus on flows with simpler physics or do not perform a systematic optimization of the underlying ML model architecture and hyperparameters. Furthermore, rigorous analysis of model robustness to noisy data and a deep dive into the interpretability of the learned representations are often lacking.

This thesis aims to fill these gaps by extending prior work, such as that by \citet{Yu2019}, to a more challenging physical problem. The focus is on a geometry-sensitive nozzle flow characterized by significant heat transfer and nonlinear shock formation, including complex shock wave–boundary layer interactions (SWBLI) as investigated by \citet{martelliFlow2020}. The specific contributions of this work, which address the identified gaps, are:

\begin{enumerate}
    \item \textbf{A Novel Loss Function:} To enhance model fidelity, a new loss function for ANNs is introduced, which combines reconstruction errors in both the latent (POD coefficient) space and the physical space.

    \item \textbf{Systematic Hyperparameter Optimization:} The BOHB algorithm \citep{falknerBOHB2018} is employed to systematically and efficiently tune the surrogate models, moving beyond ad-hoc architecture selection.

    \item \textbf{Comprehensive Robustness and Stability Analysis:} Model variance is assessed through k-fold cross-validation, and robustness is evaluated by injecting noise into the input data and analyzing the model's response.

    \item \textbf{Physics-Based Interpretability:} SHAP analysis \citep{lundberg2017unified} is incorporated to understand the influence of input features on model predictions, providing physical insights into the learned representations and building trust in the surrogate model's predictions.
\end{enumerate}

By addressing these points, this research provides a comprehensive framework and practical guidelines for developing accurate, efficient, and reliable surrogate models for complex fluid dynamics problems.
% ===================================================================
% CHAPTER 2: THEORETICAL BACKGROUND
% ===================================================================
\chapter{Theoretical Background}

\section{Nozzle Flow Modeling}
The nozzle geometry was parametrically constructed based on the reference geometry of the "$45^\circ$–$15^\circ$" conical nozzle from \citet{Back1965a}. The geometric parameters are listed in Table \ref{tab:geom_params_tese_en}. Geometric variability is introduced by adjusting the divergence angle $\theta_{div}$.

\begin{table}[h!]
  \centering
  \caption{Geometric parameters for the baseline nozzle geometry.}
  \label{tab:geom_params_tese_en}
  \begin{tabular}{ l J{3.3}{3} l l }
    \toprule
    \textbf{Parameter} & \textbf{Value} & \textbf{Units} & \textbf{Description} \\
    \midrule
    $L_i$             & 7.874   & mm  & Distance to $r_i$ center  \\
    $L_{\text{tht1}}$ & 55.880  & mm  & Convergent $r_c$ tangency distance  \\
    $L_{\text{tht2}}$ & 68.148  & mm  & Divergent $r_c$ tangency distance  \\
    $L_{\text{th}}$   & 64.872  & mm  & Length to throat  \\
    $L_{ti}$          & 22.250  & mm  & Length to $r_i$ tangency  \\
    $L$               & 185.039 & mm  & Full nozzle length  \\
    $r_c$             & 12.700  & mm  & Convergent section curvature radius  \\
    $r_i$             & 20.320  & mm  & Inlet curvature radius  \\
    $r_{in}$          & 63.500  & mm  & Inlet radius  \\
    $r_{th}$          & 20.320  & mm  & Throat radius  \\
    $r_{out}$         & 63.298  & mm  & Outlet radius  \\
    $\theta_{div}$    & 15.000  & deg & Divergence angle  \\
    $\theta_{conv}$   & 45.000  & deg & Convergence angle  \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Governing Equations}

\subsection{Quasi-1D Euler Equations (Low-Fidelity)}
The low-fidelity model is based on the quasi-one-dimensional (quasi-1D) Euler equations, which assume steady, inviscid, and axially symmetric compressible flow behavior. The vector form of the equations is:
\begin{equation}
    \frac{\partial \mathbf{U}}{\partial t} + \frac{\partial \mathbf{F}}{\partial x} = \mathbf{S}
\end{equation}
where $\mathbf{U}$, $\mathbf{F}$, and $\mathbf{S}$ are the vectors of conserved variables, flux, and the geometric source term, respectively. A finite volume method was used for the numerical solution.

\subsection{Navier-Stokes Equations (High-Fidelity)}
The high-fidelity model solves the two-dimensional Reynolds-Averaged Navier-Stokes (RANS) equations, which account for viscous and thermal effects. The conservative form reads:
\begin{equation}
  \mathbf{R}(\mathbf{U}) = \frac{\partial \mathbf{U}}{\partial t} 
  + \nabla \cdot \mathbf{F}^c(\mathbf{U}) 
  - \nabla \cdot \mathbf{F}^v(\mathbf{U}, \nabla \mathbf{U}) 
  - \mathbf{S}
\end{equation}
where $\mathbf{F}^c$ and $\mathbf{F}^v$ are the convective and viscous fluxes. The equations were solved using the open-source SU2 CFD solver, with the SST turbulence model. Verification and validation were performed through a Grid Convergence Index (GCI) analysis and comparison with experimental data.

\section{Model Order Reduction}

\subsection{Proper Orthogonal Decomposition (POD)}
POD is used to manage the high dimensionality of the flow field snapshots. It extracts a low-dimensional latent representation that preserves the most energetic modes of the data. The projection is obtained via the Singular Value Decomposition (SVD) of the snapshot matrix $\mathbf{X} = \mathbf{U} \boldsymbol{\Sigma} \mathbf{V}^T$, where the columns of $\mathbf{V}$ are the POD modes. The reduced representation is $\mathbf{\overline{X}} = \mathbf{X} \mathbf{V}_{n \times k}$, where $k \ll n$.

\section{Machine Learning Surrogate Models}

\subsection{Artificial Neural Networks (ANNs)}
ANNs are universal function approximators. We use a fully connected feedforward multilayer perceptron (MLP), whose architecture is a composition of layers that apply an affine transformation followed by a nonlinear activation function.

\subsection{Gaussian Processes (GPs)}
GP regression is a nonparametric Bayesian method that models distributions over functions. It assumes that the output values are jointly distributed as a multivariate Gaussian, defined by a mean function $\mathcal{M}$ and a covariance function (kernel) $\mathcal{K}$. We use an anisotropic Radial Basis Function (RBF) kernel.


% ===================================================================
% CHAPTER 3: METHODOLOGY
% ===================================================================
\chapter{Methodology}

\section{Framework Overview}
The proposed methodology is divided into an offline phase (model training) and an online phase (inference). Figure \ref{fig:grafico_abstrato_tese_en} summarizes the entire workflow.

\begin{figure}[h!]
    \centering
    % \includegraphics[width=\textwidth]{path/to/your/graphical_abstract_image.png}
    \caption{Graphical abstract of the proposed framework, showing the offline (training) and online (inference) stages. (Placeholder for Figure 11 from the manuscript)}
    \label{fig:grafico_abstrato_tese_en}
\end{figure}

\section{Data Generation and Numerical Experiments}
Synthetic datasets were generated using CFD simulations under two boundary condition scenarios: adiabatic wall and prescribed wall temperature. Latin Hypercube Sampling (LHS) was used to sample the input parameter space. Six distinct datasets were created, varying in size (small, medium, large) and input format (scalar or vector field). Each high-fidelity output snapshot has a dimension of $n_h = 7878$.

\section{ML-ROM Framework}

\subsection{Preprocessing and Scaling}
Input and output data are standardized using a slice-wise mean centering (for different physical quantities) and a `MaxAbsScaler` to scale the data to the $[-1, 1]$ interval.

\subsection{Dimensionality Reduction}
POD is applied to the preprocessed data. The number of retained modes, $k$, is chosen to preserve 99.99\% of the cumulative explained variance of the training data.

\subsection{Surrogate Regressors}
A regression function $\boldsymbol{\Phi}: \mathbb{R}^{k_l} \rightarrow \mathbb{R}^{k_h}$ is trained to map the projected inputs to the projected outputs.

\subsection{ANN Loss Function and Training}
An innovative hybrid loss function was formulated for ANN training, combining the error in the latent space and the error in the reconstructed physical space:
\begin{equation}
  \mathcal{L} = w_{\mathrm{recon}}\,\mathcal{L}_{\mathrm{reduced}} + (1 - w_{\mathrm{recon}})\,\mathcal{L}_{\mathrm{reconstructed}}.
\end{equation}
Training is performed using the AdamW optimizer with weight decay and a warmup-cosine decay learning rate schedule.

\subsection{Hyperparameter Optimization (HPO)}
Bayesian Optimization with Hyperband (BOHB) was used to find the optimal hyperparameter configuration for the ANNs. Table \ref{tab:hpo_search_tese_en} details the search space.

\begin{table}[h!]
  \caption{Hyperparameter search space used in BOHB tuning.}
  \label{tab:hpo_search_tese_en}
  \centering
  \begin{tabularx}{\linewidth}{r X}
  \toprule
  \textbf{Hyperparameter} & \textbf{Search Space} \\
  \midrule
  Number of Layers ($H$) & $[1, 2, \dots, 10]$ \\
  Neurons per Layer ($J_i$) & $[2, 3, \dots, 475]$ \\
  Activation Function & \textit{tanh}, \textit{relu}, \textit{GELU}, \textit{hard sigmoid}, \textit{selu}, \textit{elu}, \textit{sigmoid}, \textit{softmax}, \textit{softplus}, \textit{softsign}, \textit{swish} \\
  Weight Decay ($\lambda_{\text{wd}}$) & $[10^{-6}, 10^{-2}]$ \\
  Dropout Rate & $[0.01, 0.30]$ \\
  Learning Rate ($\eta_0$) & $[10^{-3}, 10^{-2}]$ \\
  \bottomrule
  \end{tabularx}
\end{table}


% ===================================================================
% CHAPTER 4: RESULTS AND DISCUSSION
% ===================================================================
\chapter{Results and Discussion}

\section{Hyperparameter Optimization}
The HPO analysis revealed that shallow networks (1–2 hidden layers) with a moderate number of neurons and activation functions like \textit{sigmoid}, \textit{softmax}, or \textit{hard sigmoid} consistently achieved the best performance, defined as $\text{NRMSE} < 0.10$ and $R^2 > 0.90$.

\section{Cross-Validation and Overfitting Assessment}
K-fold cross-validation ($k=5$) was used to assess generalization. The results (Table \ref{tab:kfold_results_tese_en}) showed that ANN models generally achieved higher and more stable $R^2$ values, while GP models yielded lower NRMSE on large, clean datasets but showed high variability in data-scarce regimes. This indicates that ANNs are more robust, while GPs are more accurate under ideal data conditions.

\begin{table}[h!]
\centering
\caption{Error metrics for 5-fold run, NRMSE and R$^2$, comparing both GP and ANN models.}
\label{tab:kfold_results_tese_en}
\begin{tabularx}{\linewidth}{r Y Y Y Y Y Y}
    \toprule
    \textbf{Dataset} & \multicolumn{2}{c}{\textbf{NRMSE}} & \multicolumn{2}{c}{\textbf{R$^2$}} \\
    & \textbf{GP} & \textbf{ANN}  & \textbf{GP} & \textbf{ANN} \\
    \midrule
    ADLF & 0.022 ± 0.002 & 0.026 ± 0.007 & 0.967 ± 0.007 & 0.972 ± 0.011  \\
    ADMF & 0.027 ± 0.003 & 0.035 ± 0.004 & 0.962 ± 0.004 & 0.969 ± 0.004  \\
    ADSF & 0.065 ± 0.027 & 0.074 ± 0.015 & 0.931 ± 0.018 & 0.938 ± 0.006  \\
    ADLS & 0.022 ± 0.001 & 0.029 ± 0.002 & 0.965 ± 0.007 & 0.962 ± 0.012  \\
    ADMS & 0.025 ± 0.004 & 0.037 ± 0.008 & 0.96 ± 0.004 & 0.961 ± 0.004  \\
    ADSS & 0.038 ± 0.009 & 0.039 ± 0.007 & 0.943 ± 0.012 & 0.934 ± 0.024 \\
    \midrule
    PTLF & 0.027 ± 0.002 & 0.03 ± 0.003 & 0.954 ± 0.027 & 0.969 ± 0.01 \\
    PTMF & 0.051 ± 0.039 & 0.042 ± 0.008 & 0.939 ± 0.015 & 0.955 ± 0.015  \\
    PTSF & 0.356 ± 0.192 & 0.074 ± 0.021 & 0.704 ± 0.074 & 0.876 ± 0.027  \\
    PTLS & 0.023 ± 0.001 & 0.03 ± 0.003 & 0.963 ± 0.01 & 0.967 ± 0.01  \\
    PTMS & 0.025 ± 0.005 & 0.045 ± 0.008 & 0.95 ± 0.014 & 0.944 ± 0.017  \\
    PTSS & 0.046 ± 0.009 & 0.068 ± 0.022 & 0.884 ± 0.012 & 0.886 ± 0.022  \\
    \bottomrule
\end{tabularx}
\end{table}

\section{Noise Robustness}
Controlled Gaussian noise was added to the test inputs to evaluate robustness. ANNs showed a smoother and more gradual performance degradation compared to GPs, which deteriorated rapidly, especially with small datasets. This reinforces the conclusion that ANNs offer greater robustness in noisy or scarce data scenarios.

\section{Model Interpretability (SHAP Analysis)}
SHAP analysis was used to interpret model predictions.
\begin{itemize}
    \item \textbf{Scalar-based Models:} Total pressure $p_0$ was consistently the most influential feature, while wall temperature $T_w$ had a minimal impact.
    \item \textbf{Field-based Models:} For GPs, feature importance strictly followed the energetic order of the POD modes. In contrast, ANNs occasionally assigned high relevance to low-energy modes, suggesting they exploit localized structures (like shocks) captured by these modes to improve reconstruction.
\end{itemize}

\section{2D Flow Field Reconstruction}
Both models successfully reconstructed the main flow features, including the formation of a Mach disk. However, the analysis of normalized relative error showed that ANNs provided significantly more accurate reconstructions, with smaller and more localized errors, especially near discontinuities like shock waves. The GP model tended to smooth out these sharp features.

\section{Shock-Boundary Layer Interaction Analysis}
The models were able to qualitatively capture the effects of shock-boundary layer interaction, specifically the Free Shock Separation (FSS) regime. The ANN demonstrated superior performance in reconstructing the detailed structure of the distorted velocity profiles near the wall, which is crucial for accurate nozzle performance prediction.

\section{Computational Efficiency}
The surrogate models offered drastic speed-up gains. GPs were up to $7374\times$ faster than the Q1D solver, and ANNs were up to $744\times$ faster. Compared to the high-fidelity RANS solver (SU2), the speed-ups were $537\times$ for GP and $54\times$ for ANN. This highlights the immense practical value for tasks requiring a large number of evaluations.


% ===================================================================
% CHAPTER 5: CONCLUSIONS AND FUTURE WORK
% ===================================================================
\chapter{Conclusions and Future Work}

\section{Summary of Conclusions}
This study successfully demonstrated a surrogate modeling framework for the reconstruction of complex nozzle flows. The combination of POD dimensionality reduction, ANN/GP regression, and systematic hyperparameter optimization yielded accurate, robust, and computationally efficient models. Artificial Neural Networks (ANNs), particularly shallow architectures, proved superior in terms of robustness, generalization, and ability to capture nonlinear flow features like shock waves compared to Gaussian Processes (GPs).

\section{Limitations of the Work}
Despite the promising results, the work has limitations:
\begin{itemize}
    \item The utility of low-fidelity inputs (Q1D solutions) was, in some cases, limited, with scalar-based models performing comparably.
    \item The performance of the models is heavily dependent on the availability of high-fidelity data, which is expensive to generate.
    \item Hyperparameter optimization adds significant computational overhead to the offline phase.
\end{itemize}

\section{Recommendations for Future Work}
Based on the findings and limitations, the following areas are suggested for future research:
\begin{itemize}
    \item \textbf{Multi-fidelity Modeling:} Explore more sophisticated multi-fidelity machine learning approaches that can more effectively fuse information from low- and high-fidelity solvers.
    \item \textbf{Active Learning:} Implement active learning strategies to iteratively select the most informative high-fidelity data points to simulate, reducing the overall computational cost of data generation.
    \item \textbf{Generalization to More Complex Geometries and Physics:} Extend the framework to handle unsteady (time-dependent) flows and three-dimensional geometries.
    \item \textbf{Physics-Informed ROMs (PINNs):} Investigate the use of Physics-Informed Neural Networks (PINNs), which embed the governing equations directly into the loss function, to reduce the reliance on large training datasets.
\end{itemize}

%%%%%%%%%%%================%%%%%%%%%%%
\backmatter
%%%%%%%%%%%================%%%%%%%%%%%

% ===================================================================
% BIBLIOGRAPHY
% ===================================================================
\bibliographystyle{Bibliografia/abnt2023} % Bibliography style from the manuscript
\bibliography{/Users/ppiper/Documents/Sync/thesis_doc/latex_src/Bibliografia/library.bib}% Name of your .bib file
\bibliography{}

\input{Apendices/Input_Ap01_1_0}

% -----------------------------
% Anexos - OBS: Não há neste modelo distinção numérica entre apêndice e anexo
% -----------------------------
\input{Anexos/Input_An01_1_0}

\end{document}